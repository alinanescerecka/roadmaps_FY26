{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0iVuWbfUsMq",
        "outputId": "4ee0a947-71c5-4f3a-be51-b34726f4274c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/515.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m515.2/515.2 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m71.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.3/10.3 MB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m47.6/47.6 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Install Pytorch & other libraries\n",
        "%pip install -qqq torch torchvision setuptools scikit-learn\n",
        "\n",
        "# Install Hugging Face libraries\n",
        "%pip install  --upgrade datasets -qqq accelerate hf-transfer transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368,
          "referenced_widgets": [
            "4bd07baf1cc546678a0a334c3c855128",
            "7d5fea5ab674457195a418b9bc048b3d",
            "d76dca7171df480a9af5f527bf1ae025",
            "3652958cdd884d7aa58e2a5e9d61172a",
            "0c434bb30c154a238e72f7ddc2605b62",
            "7cc0bcb5d9494a4c8744cba1c0fea760",
            "63845948d6074927939c6182a4c7d142",
            "d8db806b58ed4cc7accadf2de0010a49",
            "1e26039c847c42bb9f65055836835abe",
            "ae0c1fdb022043118f810852702b496a",
            "91700f08e41044ef848fb37e1f4f3bb1",
            "8627354a0bb14a1ca98c0c1d71723455",
            "db4f59d0fb1a4f4082de090af51ac27e",
            "8b0d3bb620c34e71a780a66a295c0402",
            "703a46e1e5114731b7cc2eeb40961418",
            "cc87e99d84c943b6a838d31573963f0c",
            "958dd15ce9cc43628eb3c52103b8c0b8",
            "595da977b8b3470cbe8ee0cefdf66c3a",
            "74ed02c81ac4496e8981d29b2f46c8b1",
            "8e330d097e2f4fdda1624644a6bd9a64",
            "a8ffb59b739940a49d37f8abf4b8086a",
            "acc74fb015b74491918ace49354f7629",
            "166da043df664a40818a238929fe62d3",
            "d3050e5292554a7eb82ac9b5abd5afeb",
            "96df38af1d8e4af38c07b4521ce9a787",
            "1dfc6ec7464e469cb43a4db07244f98f",
            "d0841d1473dc4809b501612bac99b7dd",
            "f82102b5f6f241ba8ecb62a53226e59a",
            "742fcb792557401f9e8b1793f58eba29",
            "b7d1928133e34ba6b23d4a2a40fb328b",
            "e56009ea060146ce88c42ed74595c518",
            "ae899d176a6848ebb8689d3e8c7f2e77",
            "7e2e78d6f8794e19ab679c6970be7776",
            "467ff24eed8441a197e26ee462311d38",
            "e67a91f7125f4659a04c812dd41128fd",
            "81147544ed044df8900d846b453d37a0",
            "b8172ca10543460b834d3720db66686b",
            "b4b97689f4804df59dbf6ebfa5e7ddc2",
            "905d27bea9bf4ef0adb6a1eb399303f6",
            "caaf43bef2d540bcb86780c03b72b411",
            "5eedf2f4079e44f3a4e75d95cd9cee5d",
            "a2ddaa8958ff42af891c0225b7bf3eb7",
            "7f6a1a9744bd47458becbbada041a39a",
            "e3e1e9c3d5a3474398326168e363f99d",
            "9fe4e85d3ff941e9a6c78cc52934a3e0",
            "4b665cee7c1a4ff3b59cf55486625ec2",
            "69f902ca666b49b89dc3faf6f8e7331f",
            "54d82f97e0ae4ee1b0e4d0626739fdbe",
            "08f9543110cf4e0dbd670a62e86e1893",
            "ccdbcaf74c0a46eab26ee62a7c41d691",
            "b8e95b7bf3e846dd9e078cdf73b586bd",
            "9da985c85f6e4ab7b0a463cbee01f67a",
            "29cca02ee3e94ad1b53859c0a0b1d330",
            "87d9275232fe4e6db1297ca9eafbc7d6",
            "f3432ad7bc0440a584666b2a849bfb16",
            "47975549b09945659c7af8722ba89e91",
            "9ec27634959142a4ae6809a1d73819dc",
            "8c3461eb7f594b6680f9ab8eb51db85d",
            "1b784f7c281445d3953ae71feda503da",
            "b10f81e9a8d74096aeb5c402aa2b3530",
            "767d25d39b9841c09a27df08d8550394",
            "6fd9384e808741c6b88380d295069d86",
            "981b863f48e34637b5cc8d015a6304d3",
            "7b959ba185074039b8fb2670f378a9dd",
            "4b3257079b3a4f62a486ca1e1311eede",
            "fa2c7c7d5b244b179228c1790ca6dffe"
          ]
        },
        "id": "-vQk2H4cU43r",
        "outputId": "05acd4f7-ccda-4350-d92b-d7e00b55cfaf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/418 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4bd07baf1cc546678a0a334c3c855128"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/train-00000-of-00002.parquet:   0%|          | 0.00/94.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8627354a0bb14a1ca98c0c1d71723455"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/train-00001-of-00002.parquet:   0%|          | 0.00/94.5M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "166da043df664a40818a238929fe62d3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
            "WARNING:huggingface_hub.utils._http:Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/test-00000-of-00001.parquet:   0%|          | 0.00/20.6M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "467ff24eed8441a197e26ee462311d38"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/127723 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9fe4e85d3ff941e9a6c78cc52934a3e0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/14192 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "47975549b09945659c7af8722ba89e91"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Dataset id from huggingface.co/dataset\n",
        "dataset_id = \"burtenshaw/PleIAs_common_corpus_code_classification\"\n",
        "\n",
        "# Load raw dataset\n",
        "dataset = load_dataset(dataset_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scLV2l8DeAXk",
        "outputId": "cb761466-485e-4c42-cc24-0e82028bf2b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "127723\n",
            "{'text': '/*\\n * Copyright (c) 2000 Kungliga Tekniska HÃ¶gskolan\\n * (Royal Institute of Technology, Stockholm, Sweden).\\n * All rights reserved.\\n *\\n * Redistribution and use in source and binary forms, with or without\\n * modification, are permitted provided that the following conditions\\n * are met:\\n *\\n * 1. Redistributions of source code must retain the above copyright\\n *    notice, this list of conditions and the following disclaimer.\\n *\\n * 2. Redistributions in binary form must reproduce the above copyright\\n *    notice, this list of conditions and the following disclaimer in the\\n *    documentation and/or other materials provided with the distribution.\\n *\\n * 3. Neither the name of the Institute nor the names of its contributors\\n *    may be used to endorse or promote products derived from this software\\n *    without specific prior written permission.\\n *\\n * THIS SOFTWARE IS PROVIDED BY THE INSTITUTE AND CONTRIBUTORS ``AS IS\\'\\' AND\\n * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\\n * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\\n * ARE DISCLAIMED.  IN NO EVENT SHALL THE INSTITUTE OR CONTRIBUTORS BE LIABLE\\n * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\\n * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS\\n * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)\\n * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT\\n * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY\\n * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF\\n * SUCH DAMAGE.\\n */\\n\\n#ifdef HAVE_CONFIG_H\\n#include <config.h>\\n__RCSID(\"$Heimdal: getaddrinfo_hostspec.c 14773 2005-04-12 11:29:18Z lha $\"\\n        \"$NetBSD: getaddrinfo_hostspec.c,v 1.2 2008/03/22 08:37:21 mlelstv Exp $\");\\n#endif\\n\\n#include \"roken.h\"\\n\\n/* getaddrinfo via string specifying host and port */\\n\\nint ROKEN_LIB_FUNCTION\\nroken_getaddrinfo_hostspec2(const char *hostspec,\\n\\t\\t\\t    int socktype,\\n\\t\\t\\t    int port,\\n\\t\\t\\t    struct addrinfo **ai)\\n{\\n    const char *p;\\n    char portstr[NI_MAXSERV];\\n    char host[MAXHOSTNAMELEN];\\n    struct addrinfo hints;\\n    int hostspec_len;\\n\\n    struct hst {\\n\\tconst char *prefix;\\n\\tint socktype;\\n\\tint protocol;\\n\\tint port;\\n    } *hstp, hst[] = {\\n\\t{ \"http://\", SOCK_STREAM, IPPROTO_TCP, 80 },\\n\\t{ \"http/\", SOCK_STREAM, IPPROTO_TCP, 80 },\\n\\t{ \"tcp/\", SOCK_STREAM, IPPROTO_TCP },\\n\\t{ \"udp/\", SOCK_DGRAM, IPPROTO_UDP },\\n\\t{ NULL }\\n    };\\n\\n    memset(&hints, 0, sizeof(hints));\\n\\n    hints.ai_socktype = socktype;\\n\\n    for(hstp = hst; hstp->prefix; hstp++) {\\n\\tif(strncmp(hostspec, hstp->prefix, strlen(hstp->prefix)) == 0) {\\n\\t    hints.ai_socktype = hstp->socktype;\\n\\t    hints.ai_protocol = hstp->protocol;\\n\\t    if(port == 0)\\n\\t\\tport = hstp->port;\\n\\t    hostspec += strlen(hstp->prefix);\\n\\t    break;\\n\\t}\\n    }\\n\\n    p = strchr (hostspec, \\':\\');\\n    if (p != NULL) {\\n\\tchar *end;\\n\\n\\tport = strtol (p + 1, &end, 0);\\n\\thostspec_len = p - hostspec;\\n    } else {\\n\\thostspec_len = strlen(hostspec);\\n    }\\n    snprintf (portstr, sizeof(portstr), \"%u\", port);\\n\\n    snprintf (host, sizeof(host), \"%.*s\", hostspec_len, hostspec);\\n    return getaddrinfo (host, portstr, &hints, ai);\\n}\\n\\nint ROKEN_LIB_FUNCTION\\nroken_getaddrinfo_hostspec(const char *hostspec,\\n\\t\\t\\t   int port,\\n\\t\\t\\t   struct addrinfo **ai)\\n{\\n    return roken_getaddrinfo_hostspec2(hostspec, 0, port, ai);\\n}\\n', 'labels': 'C'}\n"
          ]
        }
      ],
      "source": [
        "print(len(dataset[\"train\"]))\n",
        "print(dataset[\"train\"][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226,
          "referenced_widgets": [
            "77980a77a19743a3b01e1e47ea3a3b90",
            "bfc6758bcbe747ec83e77ad925b8e78b",
            "8a83b8840d8446d994c499af84e1fee7",
            "11b599c1921e4f59a1ac21ddcfaddf0a",
            "1332b616d70a4495aeb692a08b615107",
            "880b3739b77d49979d9fc24d891e1507",
            "58cac58eb9b64240879d43ab518f5fd6",
            "5c9b2165941f4af6a83d532a8bc91205",
            "30c9d75f864d488881fb9b0d3c2e4282",
            "9d62e6441ca84db2957320151abda191",
            "f088fd04e71e4fb6b9ee0f6f83616ab6",
            "e8ba483d62cf4c22a6e4a49f6a606760",
            "5dc5427da2fd4046b6e6736520a24fa1",
            "f6a8447dfc014e4bba47fc0ab5702b9d",
            "071b446750ef493799fe5854c9da3217",
            "4b5b8c24f9fe4107a065bb52518e5a8f",
            "d2b3c880f5e741c0803dba1802291e47",
            "41e629f128e346f0823250eba412b017",
            "58a723ec68e448cd9131aa90ad0f18f9",
            "09dbb3f04b31454dbdd5f7e3732914e5",
            "6ff627c35827433da4442cf817e6b514",
            "49256947dee24d6fa561fc2af90a4805",
            "3a573d73a1dd4fd4a8c75b0e81be3436",
            "bab33c9a84574744a90fd06596762dcf",
            "0e5ccf7ad66f42f0af7e9878883cee01",
            "8dd4a2dd98ad43809a5a4bb10086a4e1",
            "fd10073ed92c468bb5cd253baa823ebc",
            "1880b5aca0a94c9ca24ae5d4da05c60c",
            "dac40514ea9b4ae588a0319549df042a",
            "e86c935f9b9b41fdbd6c3af804e590b9",
            "fa94493567b142cbb226c6c77264d083",
            "8d00360b48d54a0487c4bd21fa13a129",
            "be6a07afc1244ffeb821af725559a3d8",
            "fe02f92c377c4587820e091f6f4b67f0",
            "deee9a576d374d0f8882efdaf0cadec9",
            "ed08617886e148279785528897048b6c",
            "1556d353e9f443ddb20b5f2bfa80040e",
            "52122882cb34418c8c8a8a62501c13f8",
            "ad11f1db0aa84d9ea6f32294edbeb0e6",
            "987da3af1bde4ea3802b463b7f51917f",
            "76f7fa8c66a24e85b4e7fa5f76add4b8",
            "34f947dbccaf42919178d28aabc96f5b",
            "24b884c7d2264fd69efaed00b9e031e9",
            "4614d15bfcec4229b32d7721d28ed4d8",
            "12588a6b648c48a29ea634ec3989f228",
            "bdad458396da416fb72f93cbba39a271",
            "f6e6646f50794127a235418e426d46ec",
            "1cd93992fc1d47f0a0e9e1f49fb85b89",
            "57d4f89012194c1b877b9c0090bad0a4",
            "fc0eddb545c34f1eabec83f417953b5b",
            "4b58d1f15569421b82c32aff27014058",
            "f949ca61b4c44dec93cb75723603acbd",
            "4e73876ac24c4159bf44bc20e21704d1",
            "a787c9a64b274d3c856abc9d862f0e90",
            "25b6b65008a3493d875dd47b63f585fb",
            "899c528efa9d4a6aa85f658ca41be7b5",
            "ca0a490e7eb44a5ca609c06bbcb5ca59",
            "4e6004d73242405f8baf22de4ae4ebef",
            "5518e23fe8824afd874def45d8a7ed3e",
            "431564cfbb1645e1994a15c8960b68dc",
            "9fe4801906ed4a4a9ccf8b373bdb5bb2",
            "60cee8ccb7314d1d8181b8a091b36aa9",
            "59b84db148114d28a5ba0b9d7385f053",
            "300a190968c84bcb8932cc55ad2b41b7",
            "29f64c67088d40908e5040f4de31daff",
            "c58b235254e94615abc455f2c39d8fd3"
          ]
        },
        "id": "nu03sFAiVBZm",
        "outputId": "97782086-3978-442f-fdc7-9efa0adc805e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "77980a77a19743a3b01e1e47ea3a3b90"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e8ba483d62cf4c22a6e4a49f6a606760"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3a573d73a1dd4fd4a8c75b0e81be3436"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/694 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fe02f92c377c4587820e091f6f4b67f0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/127723 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "12588a6b648c48a29ea634ec3989f228"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/14192 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "899c528efa9d4a6aa85f658ca41be7b5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['labels', 'input_ids', 'attention_mask'])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Model id to load the tokenizer\n",
        "model_id = \"answerdotai/ModernBERT-base\"\n",
        "\n",
        "# Load Tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "\n",
        "# Tokenize helper function\n",
        "def tokenize(batch):\n",
        "    return tokenizer(batch['text'], padding=True, truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "# Tokenize dataset\n",
        "tokenized_dataset = dataset.map(tokenize, batched=True, remove_columns=[\"text\"])\n",
        "\n",
        "tokenized_dataset[\"train\"].features.keys()\n",
        "# dict_keys(['labels', 'input_ids', 'attention_mask'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3EJxH4YsVBcW"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "# Model id to load the tokenizer\n",
        "model_id = \"answerdotai/ModernBERT-base\"\n",
        "\n",
        "# Prepare model labels - useful for inference\n",
        "labels = list(set(tokenized_dataset[\"train\"][\"labels\"]))\n",
        "num_labels = len(labels)\n",
        "label2id, id2label = dict(), dict()\n",
        "for i, label in enumerate(labels):\n",
        "    label2id[label] = str(i)\n",
        "    id2label[str(i)] = label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255,
          "referenced_widgets": [
            "771a103db25142cda7d0cd6192c8f5dd",
            "2639da8eac774e84888114021ee703ba",
            "28e9c64a55f545dc9bfee882801e2fbd",
            "4c69bf4276a44104825a3f263100ce2b",
            "f74923fe254c4fcfa4d50a6285d8564e",
            "631edf7ab9d943b6a493b75812d2586a",
            "05607086d3d54d1da9dbbb549e7350f8",
            "f2f2088649fc4deba362c36e40eac519",
            "49852af076554af8a2a9ac9726ae1a8b",
            "f9a2d272b85741568a8d9d89063b4e5f",
            "93fbdba13ef343d781174626cdc632bf",
            "967ebdced6c14a9eae284bc8f350d79e",
            "9a19e57d6f484f048f7481e00e89304d",
            "c243b63772654e0795e83d0c218a9dd9",
            "94896619e31c44f198f62ae0e38432ce",
            "46716216bce64326923b0cfa42b35ff6",
            "2f6e5cd501f54b61af9a8d8b21636c0c",
            "f1d94755643646f991fc5508a06d8e7e",
            "83920cd2a6e54ab1a40d6b3f58dbad52",
            "b7eebb33b3114abe85b911cd13650be9",
            "a499dacc80d5406fa66477e1d082b5da",
            "3eb14cb835d844e88e2ce8168c979673"
          ]
        },
        "id": "Da-JsWNlg-cO",
        "outputId": "c9ea7d20-710f-4103-d399-1ef996a42aee"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/599M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "771a103db25142cda7d0cd6192c8f5dd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/136 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "967ebdced6c14a9eae284bc8f350d79e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1mModernBertForSequenceClassification LOAD REPORT\u001b[0m from: answerdotai/ModernBERT-base\n",
            "Key               | Status     | \n",
            "------------------+------------+-\n",
            "decoder.bias      | UNEXPECTED | \n",
            "classifier.bias   | MISSING    | \n",
            "classifier.weight | MISSING    | \n",
            "\n",
            "\u001b[3mNotes:\n",
            "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
            "- MISSING\u001b[3m\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Download the model from huggingface.co/models\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_id, num_labels=num_labels, label2id=label2id, id2label=id2label,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Rb9Ab_ykVBfD"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Metric helper method\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    score = f1_score(\n",
        "            labels, predictions, labels=labels, pos_label=1, average=\"weighted\"\n",
        "        )\n",
        "    return {\"f1\": float(score) if score == 1 else score}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "MOgrfOJJVHSj",
        "outputId": "ac8b1451-9b4d-41d4-8f5f-6a1cc5e401bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'HfFolder' from 'huggingface_hub' (/usr/local/lib/python3.12/dist-packages/huggingface_hub/__init__.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2524876616.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mhuggingface_hub\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHfFolder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrainingArguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Define training args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m training_args = TrainingArguments(\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'HfFolder' from 'huggingface_hub' (/usr/local/lib/python3.12/dist-packages/huggingface_hub/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "from huggingface_hub import HfFolder\n",
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "# Define training args\n",
        "training_args = TrainingArguments(\n",
        "    output_dir= \"ModernBERT-code-classifier\",\n",
        "    per_device_train_batch_size=1,\n",
        "    per_device_eval_batch_size=1,\n",
        "    gradient_accumulation_steps=16,\n",
        "    learning_rate=5e-5,\n",
        "    num_train_epochs=5,\n",
        "    bf16=True, # bfloat16 training\n",
        "    optim=\"adamw_torch_fused\", # improved optimizer\n",
        "    # logging & evaluation strategies\n",
        "    logging_strategy=\"steps\",\n",
        "    logging_steps=100,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    save_total_limit=2,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1\",\n",
        "    # push to hub parameters\n",
        "    push_to_hub=True,\n",
        "    hub_strategy=\"every_save\",\n",
        "    hub_token=HfFolder.get_token(),\n",
        "    report_to=\"wandb\"\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgQsi3tnXJU4"
      },
      "source": [
        "# Overfitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DiwCjMY2XJci"
      },
      "outputs": [],
      "source": [
        "limited_dataset = tokenized_dataset[\"train\"].select(range(100))\n",
        "\n",
        "# Create a Trainer instance\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=limited_dataset,\n",
        "    eval_dataset=tokenized_dataset[\"test\"],\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eZMjCx_1XiC0"
      },
      "outputs": [],
      "source": [
        "# clear memory\n",
        "\n",
        "import torch\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "del trainer\n",
        "del model\n",
        "del limited_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u86h29rsXJlY"
      },
      "source": [
        "# Underfitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zOZHoke2XJtk"
      },
      "outputs": [],
      "source": [
        "# define a low learning rate\n",
        "training_args.learning_rate = 1e-7\n",
        "\n",
        "# Create a Trainer instance\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=limited_dataset,\n",
        "    eval_dataset=tokenized_dataset[\"test\"],\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2r3jOiQ1Xq-E"
      },
      "outputs": [],
      "source": [
        "# clear memory\n",
        "\n",
        "import torch\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "del trainer\n",
        "del model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FQRRGOyXKAZ"
      },
      "source": [
        "# Just right! ğŸ¥£"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QGL6NDFUXKI3"
      },
      "outputs": [],
      "source": [
        "# define a valid learning rate\n",
        "training_args.learning_rate = 5e-5\n",
        "\n",
        "# Create a Trainer instance\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=limited_dataset,\n",
        "    eval_dataset=tokenized_dataset[\"test\"],\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3pV0O3uhc2X"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9dSYxaH4VQRY"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# load model from huggingface.co/models using our repository id\n",
        "classifier = pipeline(\n",
        "    task=\"text-classification\",\n",
        "    model=\"argilla/ModernBERT-domain-classifier\",\n",
        "    device=0,\n",
        ")\n",
        "\n",
        "sample = \"\"\"def add_numbers(a, b):\n",
        "    return a + b\"\"\"\n",
        "\n",
        "classifier(sample)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}