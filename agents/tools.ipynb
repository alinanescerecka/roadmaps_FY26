{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYMN-5Pq3Bfd"
      },
      "source": [
        "# Tools in LlamaIndex\n",
        "\n",
        "\n",
        "This notebook is part of the [Hugging Face Agents Course](https://www.hf.co/learn/agents-course), a free Course from beginner to expert, where you learn to build Agents.\n",
        "\n",
        "![Agents course share](https://huggingface.co/datasets/agents-course/course-images/resolve/main/en/communication/share.png)\n",
        "\n",
        "## Let's install the dependencies\n",
        "\n",
        "We will install the dependencies for this unit."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QGiRk7hS3Bfd",
        "outputId": "a94a4635-3141-49b7-c2e0-5ab28fcb2e7a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/52.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.0/52.0 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[33mWARNING: huggingface-hub 1.4.0 does not provide the extra 'inference'\u001b[0m\u001b[33m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.4/21.4 MB\u001b[0m \u001b[31m85.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.9/11.9 MB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m303.3/303.3 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m79.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.9/63.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m93.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.6/132.6 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.0/220.0 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m330.6/330.6 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.0/51.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.0/142.0 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "opentelemetry-exporter-gcp-logging 1.11.0a0 requires opentelemetry-sdk<1.39.0,>=1.35.0, but you have opentelemetry-sdk 1.39.1 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.38.0 requires opentelemetry-exporter-otlp-proto-common==1.38.0, but you have opentelemetry-exporter-otlp-proto-common 1.39.1 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.38.0 requires opentelemetry-proto==1.38.0, but you have opentelemetry-proto 1.39.1 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.38.0 requires opentelemetry-sdk~=1.38.0, but you have opentelemetry-sdk 1.39.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install llama-index llama-index-vector-stores-chroma llama-index-llms-huggingface-api llama-index-embeddings-huggingface llama-index-tools-google -U -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GI0GmfFk3Bfe"
      },
      "source": [
        "And, let's log in to Hugging Face to use serverless Inference APIs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "aAKPiqtD3Bfe",
        "outputId": "620cc581-fd91-4be6-b774-1a8cfbc8ea52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "a71b9141f5e84d2492c1703c0fcb2cb9",
            "093ced8cbc674a19b4f4df86eaf3b096",
            "30e00f237d3346da8542e7c8fc09f512",
            "7278d1ac0ccc4107a1ca22a56edbbc81",
            "ca622ad674ad4bdb9d932e6bb22510be",
            "6f0aee0d78a042118d10c6312c793ec7",
            "3a1e93086f6d4bfe9983aa59d52366eb",
            "19fb9fb7d5354c5f9548accd9aea7b69",
            "b9ceec111a0041bebd222247ed12d76c",
            "65f26f1a18d8418da42bfd90bae4ca5d",
            "c8306343be874b8691859afd545d35f8",
            "7be6fd1341424d23a7d8e5d746f4b2e0",
            "a28139432feb4e898e21d49c8314583e",
            "c81922b72e374008ab61284b85cd8b6f",
            "4d65a6a8a9d14ceb867e580bf1fbb47b",
            "b06ac73dd6bb4a58aeabde40686b3b53",
            "fac43d456b2f4a388e1a2cbd32e08e40",
            "6e18866a1f3a47df9b74ae78d68b881d",
            "13dd486e19464cc685af4aa5216ce598",
            "b050b226c22d4ab79d7fe648d513ee02"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a71b9141f5e84d2492c1703c0fcb2cb9"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from huggingface_hub import login\n",
        "\n",
        "login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wF5BRd1N3Bfe"
      },
      "source": [
        "## Creating a FunctionTool\n",
        "\n",
        "Let's create a basic `FunctionTool` and call it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "UWMIOR9U3Bff",
        "outputId": "8c69a5ef-d023-41fa-8399-792d75d842d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Getting weather for New York\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ToolOutput(blocks=[TextBlock(block_type='text', text='The weather in New York is sunny')], tool_name='my_weather_tool', raw_input={'args': ('New York',), 'kwargs': {}}, raw_output='The weather in New York is sunny', is_error=False)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "from llama_index.core.tools import FunctionTool\n",
        "\n",
        "\n",
        "def get_weather(location: str) -> str:\n",
        "    \"\"\"Useful for getting the weather for a given location.\"\"\"\n",
        "    print(f\"Getting weather for {location}\")\n",
        "    return f\"The weather in {location} is sunny\"\n",
        "\n",
        "\n",
        "tool = FunctionTool.from_defaults(\n",
        "    get_weather,\n",
        "    name=\"my_weather_tool\",\n",
        "    description=\"Useful for getting the weather for a given location.\",\n",
        ")\n",
        "tool.call(\"New York\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCS5G_iL3Bff"
      },
      "source": [
        "## Creating a QueryEngineTool\n",
        "\n",
        "Let's now re-use the `QueryEngine` we defined in the [previous unit on tools](/tools.ipynb) and convert it into a `QueryEngineTool`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "LdFYqbPk3Bff",
        "outputId": "e8711b6c-0dd3-47b4-821b-0fe770ece397",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557,
          "referenced_widgets": [
            "93f184dcd67d401ea060c33f67c49104",
            "5331a96412ea4043bb42dcab597d2e91",
            "b63deb05647244818edc0567ef9ea874",
            "62d44896937040449dc50048b7a9b527",
            "2d1aae8914464e6fab8260666ebe5ac1",
            "8d2acd610395456e923df8d5e456bf9f",
            "52bc32dd8c8b4178bfc92b558cb53a7f",
            "c23922025d3d43c883701d8a89b3e790",
            "5590e70421d342bf86e7710063e3b734",
            "d7861a43848e48d890371104b470beba",
            "ee3e3f66d7e948af89828047d61340d1",
            "9b49bb35134b4a3ca46b030b6a02a43e",
            "d409af5eb51448f49ba2eb4e891ab308",
            "3652cad3ddbd4163b9f89c49d9bc9e27",
            "a2a5ad5aba6f4b0c8ccd13565efe33e3",
            "173c469b1f3943c49b98d3ddb327bce9",
            "25e3213a89314fe5a94b2128b6b953a8",
            "2e9aed2e49594c5097e5aca057d472b0",
            "daf210bf546a49abbc109873fd928588",
            "1a4995bf4e7c41cd809881d60d1e4a98",
            "3c96b739255749c2b362a6a363ee4f4a",
            "688a59c2a5814d33989f678c1938ded9",
            "f2d664b2ea4d495b91b3adff527377b7",
            "ba0b0200c20544aa800cc333ac760181",
            "0a734010c63d49cb84f17178e9c30871",
            "0cf25b96cfbc41e98868fa06e993a889",
            "80d0d468ac9f4dab8cde4a72cd764f90",
            "8c2e9eb0c0354f45867744a2816e6f45",
            "3111a763687244ef841cdafa523393b5",
            "219f6ed0d7b14f199188648935a0ec1b",
            "1b49b5cf8e484e719983060ae5c6db3e",
            "316a34b0dd704ed18abdae7cfdaafad5",
            "86e14f163c9742918e3a7b882ad4179d",
            "24d3d50f024847f780b0808234234ce8",
            "5b05050b3257493faa90418426108c20",
            "29a97ea07a1a473f9585fb96db11e495",
            "b08835d1a4b945cb9cd61fe5801f0845",
            "47154197df5947b9974ad8b29d81b1f8",
            "7f341f851c5347d6873c7481db1631e8",
            "6a3f7f1644784decb082a63b7e4ea148",
            "c45544c2a4534823b200b07af045f09b",
            "f21fc31cb530426688a3ad592fb24c84",
            "2e74a7c809cd4c24acdb89474e6fa8b0",
            "241e431f46054e2e8d9661d8b4ed7bf3",
            "af71a453878b4217942121fb8d1ad416",
            "c14d23161dbd449d99342e1d736f1581",
            "d6093aa8e7b14dfd8d1b278a57f580b2",
            "6c84105fb21b4669a6e1b49d691f936b",
            "ba5ef6f3baa24dd3ad50ac04275da228",
            "acd8277b1b44410da75132ece9bca313",
            "46629aa3556549f198914152e6476a80",
            "0f7efb01ff96432189a43ae1ab394424",
            "0b114c160257480880b3d30b663261c8",
            "f3ea3b5ef49f4a9998146528e0ffda87",
            "a829d8f4b0ea462b86397272e8a0f320",
            "07447e89bd794de38913b1c1688ada7d",
            "da36945ef6d841449a2620e4e6943f7d",
            "e24849564642483399acb3caf5a0922f",
            "dac05b99368640d0ad05814194713c57",
            "8ea0a2ad352e45f6ab6c9625257357ff",
            "bdaaee8d394a4bfbb2e8d2ceae58c231",
            "e4d47d7523b541c584b224b19915526d",
            "b2e3c27b18c04868a8db636e01e2fa79",
            "19985592cef0413d8206aaa29530c306",
            "c24708f624064c60bfb09718e625eb5e",
            "908cc265af8443cfb32da063aa2b4cc5",
            "6ece919102044bb5a1c8c0c0532342da",
            "a62e9bf9a97a44fd9439593307263d81",
            "b1b978b45c6d4ba182ac71592dd888a6",
            "51eab27d9f13447e971fd1a5f257b77f",
            "2f04ee775fed47449e7242b146104d59",
            "4ac519cb43194d20bb8f9abd758272b6",
            "77da89447dd94303b77adf265a3813d6",
            "92680ba506f845349823ebc745c7da9e",
            "b370db720d8f40b98a45736283ce6828",
            "f97934b6d11e4eb68589b6959e880eba",
            "7098548f0e1c4db8b346d3f9f83df463",
            "7d24c9eb4e16422c9aa57ac5d757508f",
            "5eeb8debfbd14408bfd816e1e697d3bb",
            "c62b40cfa5924669a9873bcfd298cadc",
            "2d940185b57f448d80e86a7a56a488d3",
            "355fe79208114175b521e7244f77acff",
            "ab17f8c4589d4f6caf2c632af7e59c0b",
            "9a1de5a55f3f403299c7879e76fb6afb",
            "3989927013fb4c9f942b299d6572e585",
            "e1e581dc0c6b4a9594be506e7332a03a",
            "c4f765c9296a407488336a1d893fc0b8",
            "e971292bc7b04405b418ebfa656f89c4",
            "5b39ca7982964869a984626c6481c3be",
            "afc56fc50a484c13b7884c3b8726548e",
            "a04b3dc872ef46aa9e6b406539ba46fe",
            "570fa1ecf8984c3fb4418b2a575dfb05",
            "e6c2eeac793c4319accad672925e7211",
            "670af24f11a64b78889ec98e7559acfa",
            "c8bee7289fef4614b019118a0e7039b7",
            "b628497313e24890ba6f89aa769a0fc2",
            "a8b6a34b540c43779fee340f12ffdca3",
            "7d1ebb6b0274421a9254d5420de0194d",
            "9d4654d1937a4d229ceede0e4d6d2e9c",
            "511b5b48aa1243a0977816f3058b21b6",
            "987c4ed0d30e40e8bbbcadaaa9fd0e95",
            "027b2b4d31354b82a6e8697092972b55",
            "cf045f48481849369ffc4fe8d66a8649",
            "8ea4ed7439c3464e9372bb639c97abf6",
            "4117e73d24b649e1940ff9fdc389020d",
            "87a5639e248642be88f6ddf3adaa8eb8",
            "9222cf7ee2d444b09100b72849eb0079",
            "28d6371783734f31a7a03694ac5d57f4",
            "1a45c4a976054d9199fb9db4e5ceebb3",
            "8b08b7b0b034440db72565ebbbb87d3f",
            "ac7f481bb4334722940a9415ca992e6f",
            "63630a46cd374ca79c51e073728b1949",
            "7fe4ecb882bc45ad99b63bb25eabe9ed",
            "7b175df02d54403dbba09e1a8752ec70",
            "09e1f1b48d1d41af93722683e7c657ab",
            "f890cb1c1e3243c094e5c88adcf16be6",
            "e047c241aafe44fdb8088315c23c6f78",
            "ecd60e633306401ebcbebc46f5e196e5",
            "d809be39979641b6b93aaddb1d73890c",
            "08c6b614890b40a0adf793a477de8d68",
            "93046af0266b45aa9c3c049192056042",
            "fbc51f82e2314bfb9eb0f98fd765b09b",
            "572cd925899b4229ad773422b0d6dfc1",
            "a28019f8e2584971b05745c4219180c6",
            "8f02fa194a10460d96217875c43ac05b",
            "100d6767e624480dbc9f097fc20edce5",
            "0b22f8cd754740acb48ffc5c53f88c5a",
            "049cc9df9f714efea9644ffe1ee39e2e",
            "429816a8d5a2432ca2abdfcd7e50b60a",
            "63a8397c5f4d443fa3bb20604c16e0df",
            "642157f30bc9441fb700a820b8bf8efc",
            "ee1ef87dfae24f29895c26a4e997ef6b"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "93f184dcd67d401ea060c33f67c49104"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9b49bb35134b4a3ca46b030b6a02a43e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f2d664b2ea4d495b91b3adff527377b7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "24d3d50f024847f780b0808234234ce8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/743 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "af71a453878b4217942121fb8d1ad416"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/133M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "07447e89bd794de38913b1c1688ada7d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/199 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6ece919102044bb5a1c8c0c0532342da"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "BertModel LOAD REPORT from: BAAI/bge-small-en-v1.5\n",
            "Key                     | Status     |  | \n",
            "------------------------+------------+--+-\n",
            "embeddings.position_ids | UNEXPECTED |  | \n",
            "\n",
            "Notes:\n",
            "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/366 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7d24c9eb4e16422c9aa57ac5d757508f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5b39ca7982964869a984626c6481c3be"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "511b5b48aa1243a0977816f3058b21b6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ac7f481bb4334722940a9415ca992e6f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fbc51f82e2314bfb9eb0f98fd765b09b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ToolOutput(blocks=[TextBlock(block_type='text', text='Empty Response')], tool_name='some useful name', raw_input={'input': 'Responds about research on the impact of AI on the future of work and society?'}, raw_output=Response(response='Empty Response', source_nodes=[], metadata=None), is_error=False)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "import chromadb\n",
        "\n",
        "from llama_index.core import VectorStoreIndex\n",
        "from llama_index.llms.huggingface_api import HuggingFaceInferenceAPI\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "from llama_index.core.tools import QueryEngineTool\n",
        "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
        "\n",
        "db = chromadb.PersistentClient(path=\"./alfred_chroma_db\")\n",
        "chroma_collection = db.get_or_create_collection(\"alfred\")\n",
        "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
        "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n",
        "llm = HuggingFaceInferenceAPI(model_name=\"meta-llama/Llama-3.2-3B-Instruct\")\n",
        "index = VectorStoreIndex.from_vector_store(\n",
        "    vector_store=vector_store, embed_model=embed_model\n",
        ")\n",
        "query_engine = index.as_query_engine(llm=llm)\n",
        "tool = QueryEngineTool.from_defaults(\n",
        "    query_engine=query_engine,\n",
        "    name=\"some useful name\",\n",
        "    description=\"some useful description\",\n",
        ")\n",
        "await tool.acall(\n",
        "    \"Responds about research on the impact of AI on the future of work and society?\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjnbPH9J3Bfg"
      },
      "source": [
        "## Creating Toolspecs\n",
        "\n",
        "Let's create a `ToolSpec` from the `GmailToolSpec` from the LlamaHub and convert it to a list of tools."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "eNcZ3k013Bfg",
        "outputId": "20a8ad0d-4101-4ef2-af7c-e07f6deb7355",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<llama_index.core.tools.function_tool.FunctionTool at 0x783da04fec30>,\n",
              " <llama_index.core.tools.function_tool.FunctionTool at 0x783da04f8410>,\n",
              " <llama_index.core.tools.function_tool.FunctionTool at 0x783da04f8470>,\n",
              " <llama_index.core.tools.function_tool.FunctionTool at 0x783df953fc80>,\n",
              " <llama_index.core.tools.function_tool.FunctionTool at 0x783da04f8da0>,\n",
              " <llama_index.core.tools.function_tool.FunctionTool at 0x783da04f9430>]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "from llama_index.tools.google import GmailToolSpec\n",
        "\n",
        "tool_spec = GmailToolSpec()\n",
        "tool_spec_list = tool_spec.to_tool_list()\n",
        "tool_spec_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6auoxUA3Bfg"
      },
      "source": [
        "To get a more detailed view of the tools, we can take a look at the `metadata` of each tool."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "oP9Tgsx93Bfg",
        "outputId": "fe615689-169c-4ab7-ff33-491d51030f20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "load_data load_data() -> List[llama_index.core.schema.Document]\n",
            "Load emails from the user's account.\n",
            "search_messages search_messages(query: str, max_results: Optional[int] = None)\n",
            "\n",
            "        Searches email messages given a query string and the maximum number\n",
            "        of results requested by the user\n",
            "           Returns: List of relevant message objects up to the maximum number of results.\n",
            "\n",
            "        Args:\n",
            "            query (str): The user's query\n",
            "            max_results (Optional[int]): The maximum number of search results\n",
            "            to return.\n",
            "create_draft create_draft(to: Optional[List[str]] = None, subject: Optional[str] = None, message: Optional[str] = None) -> str\n",
            "\n",
            "        Create and insert a draft email.\n",
            "           Print the returned draft's message and id.\n",
            "           Returns: Draft object, including draft id and message meta data.\n",
            "\n",
            "        Args:\n",
            "            to (Optional[str]): The email addresses to send the message to\n",
            "            subject (Optional[str]): The subject for the event\n",
            "            message (Optional[str]): The message for the event\n",
            "update_draft update_draft(to: Optional[List[str]] = None, subject: Optional[str] = None, message: Optional[str] = None, draft_id: str = None) -> str\n",
            "\n",
            "        Update a draft email.\n",
            "           Print the returned draft's message and id.\n",
            "           This function is required to be passed a draft_id that is obtained when creating messages\n",
            "           Returns: Draft object, including draft id and message meta data.\n",
            "\n",
            "        Args:\n",
            "            to (Optional[str]): The email addresses to send the message to\n",
            "            subject (Optional[str]): The subject for the event\n",
            "            message (Optional[str]): The message for the event\n",
            "            draft_id (str): the id of the draft to be updated\n",
            "get_draft get_draft(draft_id: str = None) -> str\n",
            "\n",
            "        Get a draft email.\n",
            "           Print the returned draft's message and id.\n",
            "           Returns: Draft object, including draft id and message meta data.\n",
            "\n",
            "        Args:\n",
            "            draft_id (str): the id of the draft to be updated\n",
            "send_draft send_draft(draft_id: str = None) -> str\n",
            "\n",
            "        Sends a draft email.\n",
            "           Print the returned draft's message and id.\n",
            "           Returns: Draft object, including draft id and message meta data.\n",
            "\n",
            "        Args:\n",
            "            draft_id (str): the id of the draft to be updated\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[None, None, None, None, None, None]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "[print(tool.metadata.name, tool.metadata.description) for tool in tool_spec_list]"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}